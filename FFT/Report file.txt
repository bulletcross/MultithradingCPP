
Introduction:
The problem is to compute the product of two polynomials given in the coefficient form.
Coefficient can be anything from integer to decimal including complex numbers
The basic O(n^2) running time algorithm is surpassed by using descrete Fourier transform
which have a running time of O(nlog(n)). Two sequential algorithms have been implemented, one 
with running time O(n^2) and other with running time O(nlog(n)) and two parallel algorithms
have been implemented for O(nlog(n)) version, one with OpenMP and other with C++11 threads.
Comparision has been done for the running time of different algorithms. All coding is in C++.
______________________________________________________________________________________________

Algorithm in short - O(nlog(n)):
Step 1: Input a and b(Coefficient of two polynomial)
Step 2: y1 = RecursiveFFT(a),y2=RecursiveFFT(b)
Step 3: y=y1*y2
Step 4: c = RecursiveFFTinv(y)/n;

RecursiveFFT(a):
	n=a.length
	w_n = cos(2*pi/n) + i*sin(2*pi/n)
	w=1
	a_even = a.even
	a_odd = a.odd
	y_even = RecursiveFFT(a_even)
	y_odd = RecursiveFFT(a_odd)
	for k=0 to n/2-1:
		y[k] = y_even[k] + w*y_odd[k]
		y[k+n/2] = y_even[k] - w*y_odd[k]
		w = w*w_n
	return y

RecursiveFFTinv(a):
	(CHANGE in RecursiveFFT(a)): w_n = cos(-2*pi/n) + i*sin(-2*pi/n)

possible parallelizations:
in prod_fourier - recursiveFFT(c) with 2 threads
in recursive FFT - filter + recursiveFFT with 2 threads and rest part serially after joining
in point_multiply - for loop can be parallelized
in recursiveFFTinv - similar to recursiveFFT
in recursiveFFTinv_wrapper - for loop can be parallelized
______________________________________________________________________________________________

Theoretical Analysis:
Upto recursiveFFT, derivation of result is straight forward. To prove the correctness of expression
on which recursiveFFTinv has been coded, we use the concept that summation of n roots of unity is zero.

T_1(n) = 2*T_1(n/2) + O(n) = O(nlog(n))
T_inf(n) = T_inf(n/2) + O(n) = O(n)
Parallelism = O(n)
______________________________________________________________________________________________

Program Analysis:
Template supports any type of coeffecient including complex coeffecient.
Minimum data movement has been done - optimised version of sequentialFFT.
Non 2^k case has also been dealt.
Future along with asynchronous function has been used in thread version.
An asynchronous operation like async or promise provide a future object to the creator of asynchronous 
operation. The method is blocked if future has not provided any value.

Time analysis in running.ods file sheet1 and sheet2
______________________________________________________________________________________________

Experimental Analysis:
The running time for higher input in case of sequential O(n^2) and O(nlog(n)) is contrasting where 
O(nlog(n)) beats O(n^2) at n^7. Parallel version gives a better performance than sequential O(nlog(n))
with O3 optimization. With openmp, performance is not good because of overhead.
______________________________________________________________________________________________

Conclusion:
From the observation from running time between optimized sequential and parallel code, it can be 
concluded that parallelization is good in the senario where there are many pyhsical processors available
to process tasks parellely.